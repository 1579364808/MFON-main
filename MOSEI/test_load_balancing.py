"""
æµ‹è¯•æ— æŸè´Ÿè½½å‡è¡¡åŠŸèƒ½

éªŒè¯DeepSeeké£æ ¼çš„è´Ÿè½½å‡è¡¡æ˜¯å¦èƒ½æœ‰æ•ˆè§£å†³æ¨¡æ€æƒé‡ä¸å¹³è¡¡é—®é¢˜
"""

import os
import sys
import torch
import numpy as np
import matplotlib.pyplot as plt

path = os.path.dirname(os.path.abspath(__file__))
sys.path.append(path)

import config
from models.adaptive_tva_fusion import AdaptiveTVA_fusion
from data_loader import MOSEIDataloader


def test_load_balancing():
    """
    æµ‹è¯•è´Ÿè½½å‡è¡¡åŠŸèƒ½çš„æ•ˆæœ
    
    å¯¹æ¯”å¯ç”¨å’Œæœªå¯ç”¨è´Ÿè½½å‡è¡¡æ—¶çš„æƒé‡åˆ†å¸ƒå·®å¼‚
    """
    print("ğŸ§ª æµ‹è¯•æ— æŸè´Ÿè½½å‡è¡¡åŠŸèƒ½")
    print("="*60)
    
    # æ•°æ®åŠ è½½
    batch_size = 32
    train_data = MOSEIDataloader('train', config.MOSEI.path.raw_data_path, batch_size=batch_size)
    
    # è®¾ç½®è®¾å¤‡
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    # æµ‹è¯•é…ç½®
    test_configs = [
        {
            'name': 'æœªå¯ç”¨è´Ÿè½½å‡è¡¡',
            'enable_load_balancing': False,
            'color': 'red',
            'linestyle': '-'
        },
        {
            'name': 'å¯ç”¨è´Ÿè½½å‡è¡¡ (update_rate=0.01)',
            'enable_load_balancing': True,
            'update_rate': 0.01,
            'target_balance_ratio': 0.15,
            'color': 'blue',
            'linestyle': '--'
        },
        {
            'name': 'å¯ç”¨è´Ÿè½½å‡è¡¡ (update_rate=0.05)',
            'enable_load_balancing': True,
            'update_rate': 0.05,
            'target_balance_ratio': 0.2,
            'color': 'green',
            'linestyle': ':'
        }
    ]
    
    results = {}
    
    # æµ‹è¯•æ¯ç§é…ç½®
    for test_config in test_configs:
        print(f"\nğŸ“Š æµ‹è¯•é…ç½®: {test_config['name']}")
        print("-" * 40)
        
        # åˆ›å»ºæ¨¡å‹
        model = AdaptiveTVA_fusion(
            config,
            enable_load_balancing=test_config['enable_load_balancing'],
            update_rate=test_config.get('update_rate', 0.01),
            target_balance_ratio=test_config.get('target_balance_ratio', 0.15)
        ).to(device)
        
        model.train()  # ç¡®ä¿åœ¨è®­ç»ƒæ¨¡å¼ä¸‹æµ‹è¯•è´Ÿè½½å‡è¡¡
        
        # æ”¶é›†æƒé‡ç»Ÿè®¡
        weight_history = []
        bias_history = []
        
        # æ¨¡æ‹Ÿè®­ç»ƒè¿‡ç¨‹
        num_batches = 50  # æµ‹è¯•50ä¸ªbatch
        
        for batch_idx, sample in enumerate(train_data):
            if batch_idx >= num_batches:
                break
                
            # å‡†å¤‡æ•°æ®
            text = sample['raw_text']
            vision = sample['vision'].to(device).float()
            audio = sample['audio'].to(device).float()
            
            # å‰å‘ä¼ æ’­ (åªå…³æ³¨AGMçš„æƒé‡è¾“å‡º)
            with torch.no_grad():
                # è·å–ç¼–ç å™¨è¾“å‡º
                text_repr = model.text_encoder(text)  # [bs, 768]
                vision_repr = model.vision_encoder(vision)  # [bs, 768]
                audio_repr = model.audio_encoder(audio)  # [bs, 768]
                
                # è·å–AGMæƒé‡
                guidance_weights = model.adaptive_guidance(text_repr, vision_repr, audio_repr)
                
                # ç»Ÿè®¡æƒé‡åˆ†å¸ƒ
                mean_weights = guidance_weights.mean(dim=0).cpu().numpy()
                weight_history.append(mean_weights)
                
                # è·å–åç½®ä¿¡æ¯ (å¦‚æœå¯ç”¨è´Ÿè½½å‡è¡¡)
                if test_config['enable_load_balancing']:
                    load_stats = model.adaptive_guidance.get_load_statistics()
                    bias_history.append(load_stats['modality_bias'].copy())
            
            # æ¯10ä¸ªbatchæ‰“å°ä¸€æ¬¡ç»Ÿè®¡
            if (batch_idx + 1) % 10 == 0:
                current_weights = weight_history[-1]
                print(f"  Batch {batch_idx+1:2d}: Text={current_weights[0]:.3f}, "
                      f"Vision={current_weights[1]:.3f}, Audio={current_weights[2]:.3f}")
                
                if test_config['enable_load_balancing']:
                    current_bias = bias_history[-1]
                    print(f"            Bias: Text={current_bias[0]:.4f}, "
                          f"Vision={current_bias[1]:.4f}, Audio={current_bias[2]:.4f}")
        
        # ä¿å­˜ç»“æœ
        results[test_config['name']] = {
            'weight_history': np.array(weight_history),
            'bias_history': np.array(bias_history) if bias_history else None,
            'config': test_config
        }
        
        # æ‰“å°æœ€ç»ˆç»Ÿè®¡
        final_weights = weight_history[-1]
        print(f"\n  æœ€ç»ˆæƒé‡åˆ†å¸ƒ:")
        print(f"    æ–‡æœ¬: {final_weights[0]:.3f} ({final_weights[0]*100:.1f}%)")
        print(f"    è§†è§‰: {final_weights[1]:.3f} ({final_weights[1]*100:.1f}%)")
        print(f"    éŸ³é¢‘: {final_weights[2]:.3f} ({final_weights[2]*100:.1f}%)")
        
        # è®¡ç®—æƒé‡æ–¹å·® (è¡¡é‡å¹³è¡¡ç¨‹åº¦)
        weight_variance = np.var(final_weights)
        print(f"    æƒé‡æ–¹å·®: {weight_variance:.6f} (è¶Šå°è¶Šå¹³è¡¡)")
    
    # å¯è§†åŒ–ç»“æœ
    plot_results(results)
    
    # åˆ†æç»“æœ
    analyze_results(results)


def plot_results(results):
    """å¯è§†åŒ–æƒé‡å˜åŒ–è¿‡ç¨‹"""
    
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))
    fig.suptitle('æ— æŸè´Ÿè½½å‡è¡¡æ•ˆæœå¯¹æ¯”', fontsize=16)
    
    # å­å›¾1: æ–‡æœ¬æƒé‡å˜åŒ–
    ax1 = axes[0, 0]
    for name, result in results.items():
        config = result['config']
        weights = result['weight_history']
        ax1.plot(weights[:, 0], label=name, color=config['color'], 
                linestyle=config['linestyle'], linewidth=2)
    ax1.set_title('æ–‡æœ¬æ¨¡æ€æƒé‡å˜åŒ–')
    ax1.set_xlabel('Batch')
    ax1.set_ylabel('æƒé‡')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # å­å›¾2: è§†è§‰æƒé‡å˜åŒ–
    ax2 = axes[0, 1]
    for name, result in results.items():
        config = result['config']
        weights = result['weight_history']
        ax2.plot(weights[:, 1], label=name, color=config['color'], 
                linestyle=config['linestyle'], linewidth=2)
    ax2.set_title('è§†è§‰æ¨¡æ€æƒé‡å˜åŒ–')
    ax2.set_xlabel('Batch')
    ax2.set_ylabel('æƒé‡')
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    
    # å­å›¾3: éŸ³é¢‘æƒé‡å˜åŒ–
    ax3 = axes[1, 0]
    for name, result in results.items():
        config = result['config']
        weights = result['weight_history']
        ax3.plot(weights[:, 2], label=name, color=config['color'], 
                linestyle=config['linestyle'], linewidth=2)
    ax3.set_title('éŸ³é¢‘æ¨¡æ€æƒé‡å˜åŒ–')
    ax3.set_xlabel('Batch')
    ax3.set_ylabel('æƒé‡')
    ax3.legend()
    ax3.grid(True, alpha=0.3)
    
    # å­å›¾4: æƒé‡æ–¹å·®å˜åŒ– (å¹³è¡¡ç¨‹åº¦)
    ax4 = axes[1, 1]
    for name, result in results.items():
        config = result['config']
        weights = result['weight_history']
        # è®¡ç®—æ¯ä¸ªbatchçš„æƒé‡æ–¹å·®
        variances = np.var(weights, axis=1)
        ax4.plot(variances, label=name, color=config['color'], 
                linestyle=config['linestyle'], linewidth=2)
    ax4.set_title('æƒé‡æ–¹å·®å˜åŒ– (è¶Šå°è¶Šå¹³è¡¡)')
    ax4.set_xlabel('Batch')
    ax4.set_ylabel('æ–¹å·®')
    ax4.legend()
    ax4.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('load_balancing_test_results.png', dpi=300, bbox_inches='tight')
    print(f"\nğŸ“Š å¯è§†åŒ–ç»“æœå·²ä¿å­˜åˆ°: load_balancing_test_results.png")


def analyze_results(results):
    """åˆ†ææµ‹è¯•ç»“æœ"""
    
    print("\n" + "="*60)
    print("ğŸ“ˆ è´Ÿè½½å‡è¡¡æ•ˆæœåˆ†æ")
    print("="*60)
    
    for name, result in results.items():
        weights = result['weight_history']
        
        print(f"\nğŸ” {name}:")
        
        # åˆå§‹å’Œæœ€ç»ˆæƒé‡å¯¹æ¯”
        initial_weights = weights[0]
        final_weights = weights[-1]
        
        print(f"  åˆå§‹æƒé‡: Text={initial_weights[0]:.3f}, Vision={initial_weights[1]:.3f}, Audio={initial_weights[2]:.3f}")
        print(f"  æœ€ç»ˆæƒé‡: Text={final_weights[0]:.3f}, Vision={final_weights[1]:.3f}, Audio={final_weights[2]:.3f}")
        
        # æƒé‡å˜åŒ–é‡
        weight_changes = final_weights - initial_weights
        print(f"  æƒé‡å˜åŒ–: Text={weight_changes[0]:+.3f}, Vision={weight_changes[1]:+.3f}, Audio={weight_changes[2]:+.3f}")
        
        # å¹³è¡¡ç¨‹åº¦è¯„ä¼°
        initial_variance = np.var(initial_weights)
        final_variance = np.var(final_weights)
        variance_reduction = (initial_variance - final_variance) / initial_variance * 100
        
        print(f"  åˆå§‹æ–¹å·®: {initial_variance:.6f}")
        print(f"  æœ€ç»ˆæ–¹å·®: {final_variance:.6f}")
        print(f"  æ–¹å·®å‡å°‘: {variance_reduction:+.1f}%")
        
        # å¹³è¡¡æ•ˆæœè¯„çº§
        if final_variance < 0.01:
            balance_grade = "ä¼˜ç§€"
        elif final_variance < 0.05:
            balance_grade = "è‰¯å¥½"
        elif final_variance < 0.1:
            balance_grade = "ä¸€èˆ¬"
        else:
            balance_grade = "è¾ƒå·®"
        
        print(f"  å¹³è¡¡è¯„çº§: {balance_grade}")


if __name__ == '__main__':
    test_load_balancing()
