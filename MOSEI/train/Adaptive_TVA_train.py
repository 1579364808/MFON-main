import torch
import datetime
from tqdm import tqdm
from utils import write_log, set_random_seed
from models.adaptive_tva_fusion import AdaptiveTVA_fusion
from utils import write_config
import copy


class EarlyStopping:
    """
    æ—©åœæœºåˆ¶ç±»

    ç›‘æ§éªŒè¯æŒ‡æ ‡ï¼Œå½“æŒ‡æ ‡åœ¨æŒ‡å®šçš„è€å¿ƒå€¼å†…æ²¡æœ‰æ”¹å–„æ—¶åœæ­¢è®­ç»ƒã€‚
    æ”¯æŒä¿å­˜å’Œæ¢å¤æœ€ä½³æ¨¡å‹æƒé‡ã€‚

    Args:
        patience: è€å¿ƒå€¼ï¼Œè¿ç»­å¤šå°‘ä¸ªepochæ²¡æœ‰æ”¹å–„å°±åœæ­¢
        min_delta: æœ€å°æ”¹å–„é˜ˆå€¼ï¼Œå°äºæ­¤å€¼è®¤ä¸ºæ²¡æœ‰æ”¹å–„
        monitor: ç›‘æ§çš„æŒ‡æ ‡åç§°
        mode: ç›‘æ§æ¨¡å¼ï¼Œ'min'è¡¨ç¤ºè¶Šå°è¶Šå¥½ï¼Œ'max'è¡¨ç¤ºè¶Šå¤§è¶Šå¥½
        restore_best_weights: æ˜¯å¦åœ¨æ—©åœæ—¶æ¢å¤æœ€ä½³æƒé‡
        verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯
    """

    def __init__(self, patience=2, min_delta=1e-6, monitor='val_loss',
                 mode='min', restore_best_weights=True, verbose=True):
        self.patience = patience
        self.min_delta = min_delta
        self.monitor = monitor
        self.mode = mode
        self.restore_best_weights = restore_best_weights
        self.verbose = verbose

        # å†…éƒ¨çŠ¶æ€
        self.wait = 0
        self.stopped_epoch = 0
        self.best_weights = None

        if mode == 'min':
            self.best_score = float('inf')
            self.is_better = lambda current, best: current < best - min_delta
        else:  # mode == 'max'
            self.best_score = float('-inf')
            self.is_better = lambda current, best: current > best + min_delta

    def __call__(self, current_score, model, epoch):
        """
        æ£€æŸ¥æ˜¯å¦åº”è¯¥æ—©åœ

        Args:
            current_score: å½“å‰epochçš„ç›‘æ§æŒ‡æ ‡å€¼
            model: å½“å‰æ¨¡å‹
            epoch: å½“å‰epochæ•°

        Returns:
            bool: æ˜¯å¦åº”è¯¥åœæ­¢è®­ç»ƒ
        """
        if self.is_better(current_score, self.best_score):
            # å‘ç°æ›´å¥½çš„ç»“æœ
            self.best_score = current_score
            self.wait = 0

            # ä¿å­˜æœ€ä½³æƒé‡
            if self.restore_best_weights:
                self.best_weights = copy.deepcopy(model.state_dict())

            if self.verbose:
                print(f"ğŸ“ˆ Epoch {epoch}: {self.monitor} improved to {current_score:.6f}")
        else:
            # æ²¡æœ‰æ”¹å–„
            self.wait += 1
            if self.verbose:
                print(f"ğŸ“Š Epoch {epoch}: {self.monitor} = {current_score:.6f}, "
                      f"no improvement for {self.wait}/{self.patience} epochs")

            if self.wait >= self.patience:
                self.stopped_epoch = epoch
                if self.verbose:
                    print(f"ğŸ›‘ Early stopping triggered at epoch {epoch}")
                    print(f"   Best {self.monitor}: {self.best_score:.6f}")
                return True

        return False

    def restore_best_model(self, model):
        """
        æ¢å¤æœ€ä½³æ¨¡å‹æƒé‡

        Args:
            model: è¦æ¢å¤æƒé‡çš„æ¨¡å‹
        """
        if self.restore_best_weights and self.best_weights is not None:
            model.load_state_dict(self.best_weights)
            if self.verbose:
                print(f"ğŸ”„ Restored best model weights (best {self.monitor}: {self.best_score:.6f})")
        else:
            if self.verbose:
                print("âš ï¸  No best weights to restore")


def AdaptiveTVA_train_fusion(config, metrics, seed, train_data, valid_data, test_data):
    """
    è‡ªé€‚åº”TVAèåˆæ¨¡å‹çš„è®­ç»ƒå‡½æ•°
    
    æ ¸å¿ƒåˆ›æ–°ï¼šé›†æˆè‡ªé€‚åº”å¼•å¯¼æ¨¡å—(AGM)çš„è®­ç»ƒæµç¨‹
    
    ä¸åŸå§‹TVA_train_fusionçš„åŒºåˆ«ï¼š
    1. ä½¿ç”¨AdaptiveTVA_fusionæ¨¡å‹
    2. å°†AGMå‚æ•°åŠ å…¥ä¼˜åŒ–å™¨
    3. è®°å½•å’Œåˆ†æå¼•å¯¼æƒé‡çš„åˆ†å¸ƒ
    4. æ”¯æŒå¼•å¯¼æƒé‡çš„å¯è§†åŒ–å’Œç»Ÿè®¡
    
    Args:
        config: é…ç½®å¯¹è±¡
        metrics: è¯„ä¼°æŒ‡æ ‡å¯¹è±¡
        seed: éšæœºç§å­
        train_data: è®­ç»ƒæ•°æ®åŠ è½½å™¨
        valid_data: éªŒè¯æ•°æ®åŠ è½½å™¨
    """
    print('---------------Adaptive TVA_EXP---------------')

    set_random_seed(seed)

    # æ˜¾ç¤ºé…ç½®ä¿¡æ¯
    print("ğŸ”§ ä½¿ç”¨è‡ªé€‚åº”TVAé…ç½®:")
    print(f"  æ€»è®­ç»ƒè½®æ•°: {config.MOSEI.downStream.adaptiveTVAtrain.epoch}")
    print(f"  AGMéšè—ç»´åº¦: {config.MOSEI.downStream.adaptiveTVAtrain.agm_hidden_dim}")
    print(f"  AGMå­¦ä¹ ç‡: {config.MOSEI.downStream.adaptiveTVAtrain.agm_lr}")
    print(f"  æƒé‡å¹³æ»‘: {config.MOSEI.downStream.adaptiveTVAtrain.weight_smoothing}")
    print()
    
    # ========== è®­ç»ƒé…ç½® ==========
    update_epochs = config.MOSEI.downStream.update_epochs
    
    # ========== ä½¿ç”¨è‡ªé€‚åº”TVAä¸“ç”¨é…ç½® ==========
    adaptive_config = config.MOSEI.downStream.adaptiveTVAtrain

    # å­¦ä¹ ç‡é…ç½®
    text_lr = adaptive_config.text_lr
    audio_lr = adaptive_config.audio_lr
    vision_lr = adaptive_config.vision_lr
    other_lr = adaptive_config.other_lr
    agm_lr = adaptive_config.agm_lr  # AGMä¸“ç”¨å­¦ä¹ ç‡

    # æƒé‡è¡°å‡é…ç½®
    text_decay = adaptive_config.text_decay
    audio_decay = adaptive_config.audio_decay
    vision_decay = adaptive_config.vision_decay
    other_decay = adaptive_config.other_decay
    agm_decay = adaptive_config.agm_decay  # AGMä¸“ç”¨æƒé‡è¡°å‡

    # æŸå¤±æƒé‡é…ç½®
    delta_va = adaptive_config.delta_va     # çŸ¥è¯†è’¸é¦æƒé‡
    delta_nce = adaptive_config.delta_nce   # å¯¹æ¯”å­¦ä¹ æƒé‡

    # AGMç‰¹æœ‰é…ç½®
    agm_hidden_dim = adaptive_config.agm_hidden_dim
    weight_smoothing = adaptive_config.weight_smoothing
    analyze_weights = adaptive_config.analyze_weight_distribution
    
    # ========== æ¨¡å‹åˆå§‹åŒ– ==========
    # ä¼ é€’AGMé…ç½®åˆ°æ¨¡å‹
    model = AdaptiveTVA_fusion(config, agm_hidden_dim=agm_hidden_dim).to(config.DEVICE)
    print("Adaptive TVA Fusion Model:")
    print(model)
    print(f"AGM Hidden Dimension: {agm_hidden_dim}")
    print(f"Weight Smoothing: {weight_smoothing}")

    # åŠ è½½é¢„è®­ç»ƒçš„å†»ç»“ç¼–ç å™¨
    model.load_froze()
    
    # ========== å‚æ•°åˆ†ç»„ï¼ˆå…³é”®åˆ›æ–°ï¼šåŒ…å«AGMå‚æ•°ï¼‰ ==========
    # æ–‡æœ¬ç›¸å…³å‚æ•°
    text_params = (list(model.proj_t.named_parameters()) + 
                  list(model.text_encoder.named_parameters()))
    text_params = [p for _, p in text_params]
    
    # è§†è§‰ç›¸å…³å‚æ•°
    vision_params = (list(model.proj_v.named_parameters()) +
                    list(model.vision_with_text.named_parameters()))
    vision_params = [p for _, p in vision_params]
    # åªæœ‰åœ¨ä½¿ç”¨å¯å­¦ä¹ å‘é‡æ—¶æ‰æ·»åŠ åˆ°ä¼˜åŒ–å™¨å‚æ•°ä¸­
    if model.promptv_m is not None:
        vision_params.append(model.promptv_m)

    # éŸ³é¢‘ç›¸å…³å‚æ•°
    audio_params = (list(model.proj_a.named_parameters()) +
                   list(model.audio_with_text.named_parameters()))
    audio_params = [p for _, p in audio_params]
    # åªæœ‰åœ¨ä½¿ç”¨å¯å­¦ä¹ å‘é‡æ—¶æ‰æ·»åŠ åˆ°ä¼˜åŒ–å™¨å‚æ•°ä¸­
    if model.prompta_m is not None:
        audio_params.append(model.prompta_m)
    
    # å…¶ä»–å‚æ•°ï¼ˆä¸åŒ…å«AGMï¼‰
    model_params_other = [p for n, p in list(model.named_parameters()) if '_decoder' in n]

    # AGMå‚æ•°ï¼ˆæ ¸å¿ƒåˆ›æ–°ï¼šä½¿ç”¨ä¸“ç”¨é…ç½®ï¼‰
    agm_params = list(model.adaptive_guidance.parameters())

    # ========== ä¼˜åŒ–å™¨é…ç½®ï¼ˆç²¾ç»†åŒ–å‚æ•°åˆ†ç»„ï¼‰ ==========
    optimizer_grouped_parameters = [
        {'params': text_params, 'weight_decay': text_decay, 'lr': text_lr},
        {'params': audio_params, 'weight_decay': audio_decay, 'lr': audio_lr},
        {'params': vision_params, 'weight_decay': vision_decay, 'lr': vision_lr},
        {'params': model_params_other, 'weight_decay': other_decay, 'lr': other_lr},
        {'params': agm_params, 'weight_decay': agm_decay, 'lr': agm_lr}  # AGMä¸“ç”¨é…ç½®
    ]

    print(f"å‚æ•°åˆ†ç»„é…ç½®:")
    print(f"  æ–‡æœ¬å‚æ•°: lr={text_lr}, decay={text_decay}")
    print(f"  éŸ³é¢‘å‚æ•°: lr={audio_lr}, decay={audio_decay}")
    print(f"  è§†è§‰å‚æ•°: lr={vision_lr}, decay={vision_decay}")
    print(f"  å…¶ä»–å‚æ•°: lr={other_lr}, decay={other_decay}")
    print(f"  AGMå‚æ•°: lr={agm_lr}, decay={agm_decay}")  # æ–°å¢æ—¥å¿—
    optimizer = torch.optim.Adam(optimizer_grouped_parameters)
    
    # ========== æ—¥å¿—é…ç½® ==========
    log_path = (config.LOGPATH + "MOSEI_AdaptiveTVA_Train." +
               datetime.datetime.now().strftime('%Y-%m-%d-%H%M%S') + '.log')
    write_config(config, log_path)
    
    # ========== æ—©åœæœºåˆ¶åˆå§‹åŒ– ==========
    early_stopping = None
    if adaptive_config.early_stopping:
        early_stopping = EarlyStopping(
            patience=adaptive_config.early_stopping_patience,
            min_delta=adaptive_config.early_stopping_min_delta,
            monitor=adaptive_config.early_stopping_monitor,
            mode=adaptive_config.early_stopping_mode,
            restore_best_weights=adaptive_config.early_stopping_restore_best,
            verbose=True
        )
        print(f"ğŸ›‘ æ—©åœæœºåˆ¶å·²å¯ç”¨:")
        print(f"   ç›‘æ§æŒ‡æ ‡: {adaptive_config.early_stopping_monitor}")
        print(f"   è€å¿ƒå€¼: {adaptive_config.early_stopping_patience} epochs")
        print(f"   æœ€å°æ”¹å–„é˜ˆå€¼: {adaptive_config.early_stopping_min_delta}")
        print()

    # ========== è®­ç»ƒå¾ªç¯ ==========
    best_loss = 1e8
    guidance_stats_history = []  # è®°å½•å¼•å¯¼æƒé‡ç»Ÿè®¡å†å²
    training_stopped_early = False  # æ—©åœæ ‡å¿—

    for epoch in range(1, adaptive_config.epoch + 1):  # ä½¿ç”¨è‡ªé€‚åº”é…ç½®çš„epochæ•°
        model.train()
        left_epochs = update_epochs
        
        # ç”¨äºç»Ÿè®¡æœ¬epochçš„å¼•å¯¼æƒé‡
        epoch_guidance_weights = []
        
        bar = tqdm(train_data, disable=False)
        for index, sample in enumerate(bar):
            bar.set_description("Epoch:%d|" % epoch)
            
            if left_epochs == update_epochs:
                optimizer.zero_grad()
            left_epochs -= 1
            
            # ========== æ•°æ®å‡†å¤‡ ==========
            text = sample['raw_text']
            vision = sample['vision'].clone().detach().to(config.DEVICE).float()
            audio = sample['audio'].clone().detach().to(config.DEVICE).float()
            label = sample['labels']['M'].clone().detach().to(config.DEVICE).float()
            
            # ========== å‰å‘ä¼ æ’­ï¼ˆæ ¸å¿ƒåˆ›æ–°ï¼šè¿”å›å¼•å¯¼æƒé‡ï¼‰ ==========
            pred, (loss_v, loss_a, loss_nce, guidance_weights) = model(
                text, vision, audio, mode='train'
            )
            
            # æ”¶é›†å¼•å¯¼æƒé‡ç”¨äºåˆ†æ
            epoch_guidance_weights.append(guidance_weights.detach().cpu())
            
            # ========== æŸå¤±è®¡ç®— ==========
            # ä¸»ä»»åŠ¡æŸå¤±ï¼ˆæƒ…æ„Ÿå›å½’ï¼‰
            main_loss = torch.nn.MSELoss()(pred, label.squeeze())
            
            # æ€»æŸå¤±ï¼šä¸»ä»»åŠ¡ + çŸ¥è¯†è’¸é¦ + å¯¹æ¯”å­¦ä¹ 
            total_loss = (main_loss + 
                         delta_va * (loss_v + loss_a) + 
                         delta_nce * loss_nce)
            
            total_loss.backward()
            
            if not left_epochs:
                optimizer.step()
                left_epochs = update_epochs
                
        # å¤„ç†æœ€åä¸€ä¸ªbatch
        if not left_epochs:
            optimizer.step()
        
        # ========== éªŒè¯å’Œä¿å­˜ ==========
        # æ¯è½®è®­ç»ƒåè¯„ä¼°æ‰€æœ‰æ•°æ®é›†å¹¶æ‰“å°ç»“æœ
        train_results, train_loss = eval_adaptive(model, metrics, train_data, config.DEVICE)
        valid_results, valid_loss = eval_adaptive(model, metrics, valid_data, config.DEVICE)
        test_results, test_loss = eval_adaptive(model, metrics, test_data, config.DEVICE)

        # æ‰“å°å®Œæ•´çš„è¯„ä¼°ç»“æœ
        print(f"\nğŸ“Š Epoch {epoch}/{adaptive_config.epoch} å®Œæ•´è¯„ä¼°ç»“æœ:")
        print("=" * 80)

        # è®­ç»ƒé›†ç»“æœ
        print("ğŸ”µ è®­ç»ƒé›†ç»“æœ:")
        print(f"   Loss: {train_results['Loss']:.6f}")
        print(f"   MAE: {train_results['MAE']:.6f}")
        print(f"   Corr: {train_results['Corr']:.6f}")
        print(f"   Has0_acc_2: {train_results['Has0_acc_2']:.6f}")
        print(f"   Has0_F1_score: {train_results['Has0_F1_score']:.6f}")
        print(f"   Non0_acc_2: {train_results['Non0_acc_2']:.6f}")
        print(f"   Non0_F1_score: {train_results['Non0_F1_score']:.6f}")
        print(f"   Mult_acc_5: {train_results['Mult_acc_5']:.6f}")
        print(f"   Mult_acc_7: {train_results['Mult_acc_7']:.6f}")

        # éªŒè¯é›†ç»“æœ
        print("ğŸŸ¡ éªŒè¯é›†ç»“æœ:")
        print(f"   Loss: {valid_results['Loss']:.6f}")
        print(f"   MAE: {valid_results['MAE']:.6f}")
        print(f"   Corr: {valid_results['Corr']:.6f}")
        print(f"   Has0_acc_2: {valid_results['Has0_acc_2']:.6f}")
        print(f"   Has0_F1_score: {valid_results['Has0_F1_score']:.6f}")
        print(f"   Non0_acc_2: {valid_results['Non0_acc_2']:.6f}")
        print(f"   Non0_F1_score: {valid_results['Non0_F1_score']:.6f}")
        print(f"   Mult_acc_5: {valid_results['Mult_acc_5']:.6f}")
        print(f"   Mult_acc_7: {valid_results['Mult_acc_7']:.6f}")

        # æµ‹è¯•é›†ç»“æœ
        print("ğŸ”´ æµ‹è¯•é›†ç»“æœ:")
        print(f"   Loss: {test_results['Loss']:.6f}")
        print(f"   MAE: {test_results['MAE']:.6f}")
        print(f"   Corr: {test_results['Corr']:.6f}")
        print(f"   Has0_acc_2: {test_results['Has0_acc_2']:.6f}")
        print(f"   Has0_F1_score: {test_results['Has0_F1_score']:.6f}")
        print(f"   Non0_acc_2: {test_results['Non0_acc_2']:.6f}")
        print(f"   Non0_F1_score: {test_results['Non0_F1_score']:.6f}")
        print(f"   Mult_acc_5: {test_results['Mult_acc_5']:.6f}")
        print(f"   Mult_acc_7: {test_results['Mult_acc_7']:.6f}")

        # ä½¿ç”¨éªŒè¯é›†ç»“æœè¿›è¡Œåç»­å¤„ç†
        eval_results = valid_results
        result_loss = valid_loss

        # åˆ†ææœ¬epochçš„å¼•å¯¼æƒé‡åˆ†å¸ƒ
        if epoch_guidance_weights:
            epoch_weights = torch.cat(epoch_guidance_weights, dim=0)  # [total_samples, 3]
            guidance_analysis = model.analyze_guidance_weights(epoch_weights)

            # ğŸ†• è·å–è´Ÿè½½å‡è¡¡ç»Ÿè®¡
            load_balance_stats = model.adaptive_guidance.get_load_statistics()
            guidance_analysis['load_balance_stats'] = load_balance_stats
            guidance_stats_history.append(guidance_analysis)

            # è®°å½•å¼•å¯¼æƒé‡ç»Ÿè®¡
            guidance_log = (f"Epoch {epoch} Guidance Analysis:\n"
                          f"  Mean weights - Text: {guidance_analysis['mean_text_weight']:.3f}, "
                          f"Vision: {guidance_analysis['mean_vision_weight']:.3f}, "
                          f"Audio: {guidance_analysis['mean_audio_weight']:.3f}\n"
                          f"  Dominant counts - Text: {guidance_analysis['text_dominant_count']}, "
                          f"Vision: {guidance_analysis['vision_dominant_count']}, "
                          f"Audio: {guidance_analysis['audio_dominant_count']}")

            # ğŸ†• æ·»åŠ è´Ÿè½½å‡è¡¡ä¿¡æ¯
            if model.adaptive_guidance.enable_load_balancing:
                balance_log = (f"  Load Balancing Status:\n"
                             f"    Modality bias - Text: {load_balance_stats['modality_bias'][0]:.4f}, "
                             f"Vision: {load_balance_stats['modality_bias'][1]:.4f}, "
                             f"Audio: {load_balance_stats['modality_bias'][2]:.4f}\n"
                             f"    Load history - Text: {load_balance_stats['load_history'][0]:.3f}, "
                             f"Vision: {load_balance_stats['load_history'][1]:.3f}, "
                             f"Audio: {load_balance_stats['load_history'][2]:.3f}\n"
                             f"    Target balance ratio: {load_balance_stats['target_balance_ratio']:.3f}")
                guidance_log += "\n" + balance_log

            print(guidance_log)
            write_log(guidance_log, log_path)

        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if result_loss < best_loss:
            best_loss = result_loss
            model.save_model()
            print(f"\nğŸ‰ æ–°çš„æœ€ä½³æ¨¡å‹å·²ä¿å­˜! (éªŒè¯é›† Best Loss: {best_loss:.6f})")

            # è®°å½•æœ€ä½³æ¨¡å‹çš„å¼•å¯¼æƒé‡åˆ†å¸ƒ
            if epoch_guidance_weights:
                best_guidance_log = f"Best model guidance distribution saved at epoch {epoch}"
                write_log(best_guidance_log, log_path)
        else:
            print(f"\nğŸ“ˆ å½“å‰æœ€ä½³: éªŒè¯é›† Loss: {best_loss:.6f}")
        print("=" * 80)

        # ========== æ—©åœæ£€æŸ¥ ==========
        if early_stopping is not None:
            # æ ¹æ®é…ç½®çš„ç›‘æ§æŒ‡æ ‡è¿›è¡Œæ—©åœæ£€æŸ¥
            if adaptive_config.early_stopping_monitor == 'val_loss':
                monitor_value = result_loss
            elif adaptive_config.early_stopping_monitor == 'val_acc':
                # å‡è®¾ä½¿ç”¨Has0_acc_2ä½œä¸ºå‡†ç¡®ç‡æŒ‡æ ‡
                monitor_value = eval_results.get('Has0_acc_2', 0.0)
            elif adaptive_config.early_stopping_monitor == 'val_f1':
                # å‡è®¾ä½¿ç”¨Has0_F1_scoreä½œä¸ºF1æŒ‡æ ‡
                monitor_value = eval_results.get('Has0_F1_score', 0.0)
            else:
                monitor_value = result_loss  # é»˜è®¤ä½¿ç”¨éªŒè¯æŸå¤±

            # æ£€æŸ¥æ˜¯å¦åº”è¯¥æ—©åœ
            if early_stopping(monitor_value, model, epoch):
                training_stopped_early = True
                early_stop_log = (f"ğŸ›‘ Training stopped early at epoch {epoch}\n"
                                f"   Best {adaptive_config.early_stopping_monitor}: {early_stopping.best_score:.6f}\n"
                                f"   No improvement for {adaptive_config.early_stopping_patience} consecutive epochs")
                print(early_stop_log)
                write_log(early_stop_log, log_path)

                # æ¢å¤æœ€ä½³æ¨¡å‹æƒé‡
                if adaptive_config.early_stopping_restore_best:
                    early_stopping.restore_best_model(model)
                    model.save_model(name='early_stopped_best')
                    restore_log = "ğŸ”„ Best model weights restored and saved"
                    print(restore_log)
                    write_log(restore_log, log_path)

                break  # è·³å‡ºè®­ç»ƒå¾ªç¯

        # è®°å½•è®­ç»ƒç»“æœ
        log_info = {
            'epoch': epoch,
            'train_loss': total_loss.item(),
            'eval_loss': result_loss,
            **eval_results
        }
        write_log(log_info, log_path)
    
    # ========== è®­ç»ƒå®Œæˆæ€»ç»“ ==========
    training_summary = {
        'guidance_stats_history': guidance_stats_history,
        'stopped_early': training_stopped_early,
        'total_epochs': epoch,
        'best_loss': best_loss
    }

    if training_stopped_early:
        training_summary['early_stop_epoch'] = early_stopping.stopped_epoch
        training_summary['best_monitor_score'] = early_stopping.best_score

        final_summary = (f"\nğŸ¯ è®­ç»ƒå®Œæˆæ€»ç»“:\n"
                        f"   æ—©åœè§¦å‘: æ˜¯ (ç¬¬ {early_stopping.stopped_epoch} epoch)\n"
                        f"   æœ€ä½³ {adaptive_config.early_stopping_monitor}: {early_stopping.best_score:.6f}\n"
                        f"   æ€»è®­ç»ƒè½®æ•°: {epoch}/{adaptive_config.epoch}")
    else:
        final_summary = (f"\nğŸ¯ è®­ç»ƒå®Œæˆæ€»ç»“:\n"
                        f"   æ—©åœè§¦å‘: å¦\n"
                        f"   å®Œæ•´è®­ç»ƒè½®æ•°: {epoch}\n"
                        f"   æœ€ä½³éªŒè¯æŸå¤±: {best_loss:.6f}")

    print(final_summary)
    write_log(final_summary, log_path)

    return training_summary  # è¿”å›å®Œæ•´çš„è®­ç»ƒæ€»ç»“


def eval_adaptive(model, metrics, eval_data, device):
    """
    è‡ªé€‚åº”TVAæ¨¡å‹çš„è¯„ä¼°å‡½æ•°
    
    Args:
        model: è‡ªé€‚åº”TVAèåˆæ¨¡å‹
        metrics: è¯„ä¼°æŒ‡æ ‡å¯¹è±¡
        eval_data: è¯„ä¼°æ•°æ®åŠ è½½å™¨
        device: è®¡ç®—è®¾å¤‡
        
    Returns:
        eval_results: è¯„ä¼°ç»“æœå­—å…¸
        avg_loss: å¹³å‡æŸå¤±
    """
    model.eval()
    total_loss = 0.0
    total_samples = 0
    
    with torch.no_grad():
        pred_list = []
        truth_list = []
        guidance_weights_list = []
        
        for sample in eval_data:
            text = sample['raw_text']
            vision = sample['vision'].clone().detach().to(device).float()
            audio = sample['audio'].clone().detach().to(device).float()
            label = sample['labels']['M'].clone().detach().to(device).float()
            
            # æ¨ç†æ¨¡å¼ï¼šè¿”å›é¢„æµ‹å’Œå¼•å¯¼æƒé‡
            pred, guidance_weights = model(text, vision, audio, mode='eval')
            
            # è®¡ç®—æŸå¤±
            loss = torch.nn.MSELoss()(pred, label.squeeze())
            total_loss += loss.item() * len(label)
            total_samples += len(label)
            
            # æ”¶é›†ç»“æœ
            pred_list.append(pred.cpu())
            truth_list.append(label.cpu())
            guidance_weights_list.append(guidance_weights.cpu())
        
        # åˆå¹¶ç»“æœ
        all_preds = torch.cat(pred_list).squeeze()
        all_truths = torch.cat(truth_list).squeeze()
        all_guidance_weights = torch.cat(guidance_weights_list, dim=0)
        
        # è®¡ç®—è¯„ä¼°æŒ‡æ ‡
        eval_results = metrics.eval_mosei_regression(all_truths, all_preds)
        
        # åˆ†æå¼•å¯¼æƒé‡åˆ†å¸ƒ
        guidance_analysis = model.analyze_guidance_weights(all_guidance_weights)
        eval_results.update({
            'guidance_text_weight': guidance_analysis['mean_text_weight'],
            'guidance_vision_weight': guidance_analysis['mean_vision_weight'],
            'guidance_audio_weight': guidance_analysis['mean_audio_weight']
        })
    
    model.train()
    return eval_results, total_loss / total_samples


def AdaptiveTVA_test_fusion(config, metrics, test_data):
    """
    è‡ªé€‚åº”TVAèåˆæ¨¡å‹çš„æµ‹è¯•å‡½æ•°
    
    Args:
        config: é…ç½®å¯¹è±¡
        metrics: è¯„ä¼°æŒ‡æ ‡å¯¹è±¡
        test_data: æµ‹è¯•æ•°æ®åŠ è½½å™¨
    """
    log_path = (config.LOGPATH + "MOSEI_AdaptiveTVA_Test." +
               datetime.datetime.now().strftime('%Y-%m-%d-%H%M%S') + '.log')
    write_config(config, log_path)
    
    # åŠ è½½æ¨¡å‹
    model = AdaptiveTVA_fusion(config).to(config.DEVICE)
    model.load_froze()
    model.load_model()
    
    # æµ‹è¯•
    result, loss = eval_adaptive(model, metrics, test_data, config.DEVICE)
    
    # è®°å½•ç»“æœ
    log = ('\nAdaptive TVA Test Results:\n'
           f'\tHas0_acc_2: {result["Has0_acc_2"]}\n'
           f'\tHas0_F1_score: {result["Has0_F1_score"]}\n'
           f'\tNon0_acc_2: {result["Non0_acc_2"]}\n'
           f'\tNon0_F1_score: {result["Non0_F1_score"]}\n'
           f'\tMult_acc_5: {result["Mult_acc_5"]}\n'
           f'\tMult_acc_7: {result["Mult_acc_7"]}\n'
           f'\tMAE: {result["MAE"]}\n'
           f'\tCorr: {result["Corr"]}\n'
           f'\tLoss: {loss}\n'
           f'\tGuidance - Text: {result["guidance_text_weight"]:.3f}, '
           f'Vision: {result["guidance_vision_weight"]:.3f}, '
           f'Audio: {result["guidance_audio_weight"]:.3f}\n'
           '------------------------------------------')
    
    print(log)
    write_log(log, log_path)
